{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try: [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
    "except: pass\n",
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding, ImageShowCV2\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate, RandomSharpen\n",
    "from mltu.annotations.images import CVImage\n",
    "\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CERMetric, WERMetric\n",
    "\n",
    "from model import train_model\n",
    "from mconfigs import ModelConfigs\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is designed to prepare a dataset for a machine-learning model. The dataset includes images of handwritten text along with the corresponding transcriptions. Initially, the code specifies the locations of the text file and the folder containing the images. It then initializes three variables: Dataset, vocab, and max_len.\n",
    "\n",
    "Next, the code opens and reads all the lines from the text file. For each line, it checks if the line starts with \"#\" or if the third word is \"err\"; if either condition is met, the line is skipped. Otherwise, it extracts the first three and first eight letters of the first word in the line to construct the folder path where the image is stored. It also generates a file name by appending \".png\" to the first word. The text written in the image, which is the last word in the line, is also extracted and the newline character at the end is removed.\n",
    "\n",
    "Finally, the code adds the image path and the corresponding text label to the Dataset. It also updates the vocab with all the characters in the label and keeps track of the length of the longest label encountered so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16777/16777 [00:02<00:00, 7036.54it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences_txt_path = os.path.join(\"Datasets\", \"IAM_Sentences\", \"ascii\", \"sentences.txt\")\n",
    "sentences_folder_path = os.path.join(\"Datasets\", \"IAM_Sentences\", \"sentences\")\n",
    "\n",
    "dataset, vocab, max_len = [], set(), 0\n",
    "words = open(sentences_txt_path, \"r\").readlines()\n",
    "for line in tqdm(words):\n",
    "    if line.startswith(\"#\"):\n",
    "        continue\n",
    "\n",
    "    line_split = line.split(\" \")\n",
    "    if line_split[2] == \"err\":\n",
    "        continue\n",
    "\n",
    "    folder1 = line_split[0][:3]\n",
    "    folder2 = \"-\".join(line_split[0].split(\"-\")[:2])\n",
    "    file_name = line_split[0] + \".png\"\n",
    "    label = line_split[-1].rstrip(\"\\n\")\n",
    "\n",
    "    # replace \"|\" with \" \" in label\n",
    "    label = label.replace(\"|\", \" \")\n",
    "\n",
    "    rel_path = os.path.join(sentences_folder_path, folder1, folder2, file_name)\n",
    "    if not os.path.exists(rel_path):\n",
    "        print(f\"File not found: {rel_path}\")\n",
    "        continue\n",
    "\n",
    "    dataset.append([rel_path, label])\n",
    "    vocab.update(list(label))\n",
    "    max_len = max(max_len, len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, the Dataset must be preprocessed and prepared for use in the model. This involves tasks such as reading images, converting the images of handwritten sentences into a suitable format, indexing labels, padding labels, and dividing the Dataset into training and testing sets. Similarly to before, I am performing these steps using a custom DataProvider object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ModelConfigs object to store model configurations\n",
    "configs = ModelConfigs()\n",
    "\n",
    "# Save vocab and maximum text length to configs\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = max_len\n",
    "configs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data provider for the dataset\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=True),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_data_provider, val_data_provider = data_provider.split(split = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, when training machine learning models, it's crucial to apply data augmentation techniques to achieve better training results. I am using RandomBrightness, RandomErodeDilate, and RandomSharpen augmentors on the training data provider object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment training data with random brightness, rotation and erode/dilate\n",
    "train_data_provider.augmentors = [\n",
    "    RandomBrightness(), \n",
    "    RandomErodeDilate(),\n",
    "    RandomSharpen(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Defining Model Architecture:\n",
    "\n",
    "Once the Dataset is prepared, the next step is to design and train a machine-learning model using TensorFlow and the CTC loss function. This involves selecting an appropriate model architecture and choosing hyperparameters such as the learning rate and batch size. Here are a few recommendations for creating the model:\n",
    "\n",
    "Define the Input and Output Layers:\n",
    "The input layer of the model should be a 4D tensor with dimensions [batch size, width, height, channels], where the batch size is the number of images in a batch, width and height are the dimensions of the images, and channels represent the number of color channels in the images (1 for grayscale, 3 for RGB).\n",
    "\n",
    "Add the CNN Layers:\n",
    "The CNN layers of the model should be responsible for extracting features from the images. A typical architecture for the CNN layers includes a combination of convolutional, pooling, and fully-connected (dense) layers.\n",
    "\n",
    "Add the RNN Layers:\n",
    "The RNN layers of the model should be responsible for processing the sequence of features and predicting the characters in the text. A common type of RNN to use for this task is a long short-term memory (LSTM) network.\n",
    "\n",
    "Compile the Model:\n",
    "Once the CNN and RNN layers have been defined, the model can be compiled using the CTC loss function and an optimizer such as Adam.\n",
    "\n",
    "By following these steps, you can design a robust machine learning model for recognizing handwritten text from images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model, it can be trained on the training set using an optimization algorithm such as Adam. During training, the model will make predictions on the input data. Utilizing the CTC loss function, the model will update to reduce the disparity between the estimated values and the actual labels.\n",
    "\n",
    "We will use the following code to create the model, compile it, define the optimizer, loss, metrics, and callbacks, and initiate the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_2/kernel:0' shape=(1, 1, 3, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_5/kernel:0' shape=(1, 1, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 32, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\Documents\\Fontys\\AI\\AIforSociety\\.venv\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_8/kernel:0' shape=(3, 3, 32, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_10/kernel:0' shape=(1, 1, 32, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_12/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_13/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_14/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_15/kernel:0' shape=(1, 1, 64, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_16/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_17/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_18/kernel:0' shape=(1, 1, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_19/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_20/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_21/kernel:0' shape=(1, 1, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_22/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'conv2d_23/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.layers' has no attribute 'LSTM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating TensorFlow model architecture\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\Fontys\\AI\\AIforSociety\\Python\\WW2_letter_tool\\model.py:32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(input_dim, output_dim, activation, dropout)\u001b[0m\n\u001b[0;32m     28\u001b[0m x9 \u001b[38;5;241m=\u001b[39m residual_block(x8, \u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39mactivation, skip_conv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dropout\u001b[38;5;241m=\u001b[39mdropout)\n\u001b[0;32m     30\u001b[0m squeezed \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mReshape((x9\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m*\u001b[39m x9\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], x9\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))(x9)\n\u001b[1;32m---> 32\u001b[0m blstm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayer(\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m(\u001b[38;5;241m256\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(squeezed)\n\u001b[0;32m     33\u001b[0m blstm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDropout(dropout)(blstm)\n\u001b[0;32m     35\u001b[0m blstm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayer(layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(blstm)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.layers' has no attribute 'LSTM'"
     ]
    }
   ],
   "source": [
    "# Creating TensorFlow model architecture\n",
    "model = train_model(\n",
    "    input_dim = (configs.height, configs.width, 3),\n",
    "    output_dim = len(configs.vocab),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model and print summary\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate), \n",
    "    loss=CTCloss(), \n",
    "    metrics=[\n",
    "        CERMetric(vocabulary=configs.vocab),\n",
    "        WERMetric(vocabulary=configs.vocab)\n",
    "        ],\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "earlystopper = EarlyStopping(monitor=\"val_CER\", patience=20, verbose=1, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5.keras\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "trainLogger = TrainLogger(configs.model_path)\n",
    "tb_callback = TensorBoard(f\"{configs.model_path}/logs\", update_freq=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, min_delta=1e-10, patience=5, verbose=1, mode=\"auto\")\n",
    "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_data_provider,\n",
    "    validation_data=val_data_provider,\n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
    "    workers=configs.train_workers\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
